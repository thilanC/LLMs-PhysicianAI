{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aobOdfIXRiUH",
        "outputId": "786cf4f9-eb93-4e3f-f3d8-67809b1bcebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZMjbPtyXl8",
        "outputId": "d464e1eb-0c41-4378-8eb2-acce03ddcde1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jan 26 18:37:04 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQlQ4ZWgcXDW",
        "outputId": "11c140a3-541e-46a3-d2cb-dcf45a501b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.20 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "xformers 0.0.20 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qqq torch==2.0.1 --progress-bar off\n",
        "!pip install -qqq transformers==4.31.0 --progress-bar off\n",
        "!pip install -qqq langchain==0.0.266 --progress-bar off\n",
        "!pip install -qqq xformers==0.0.20 --progress-bar off\n",
        "!pip install -qqq sentence_transformers==2.2.2 --progress-bar off\n",
        "!pip install -qqq InstructorEmbedding==1.0.1 --progress-bar off\n",
        "# Pip install necessary package\n",
        "!pip install --upgrade --quiet  pgvector\n",
        "!pip install --upgrade --quiet  langchain-openai\n",
        "!pip install --upgrade --quiet  psycopg2-binary\n",
        "!pip install --upgrade --quiet  tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPtKPZ2agzev",
        "outputId": "fa5edd1b-ca08-4f43-d960-62fd2d93613c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting auto-gptq\n",
            "  Downloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.22.0 (from auto-gptq)\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from auto-gptq)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Collecting rouge (from auto-gptq)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting gekko (from auto-gptq)\n",
            "  Downloading gekko-1.0.6-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.1.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.1)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.31.0)\n",
            "Collecting peft>=0.5.0 (from auto-gptq)\n",
            "  Downloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->auto-gptq) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto-gptq) (12.3.101)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.13.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->auto-gptq)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.4.1)\n",
            "Collecting multiprocess (from datasets->auto-gptq)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Installing collected packages: rouge, gekko, dill, multiprocess, datasets, accelerate, peft, auto-gptq\n",
            "Successfully installed accelerate-0.26.1 auto-gptq-0.6.0 datasets-2.16.1 dill-0.3.7 gekko-1.0.6 multiprocess-0.70.15 peft-0.7.1 rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install auto-gptq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vH5IpjeNflMU",
        "outputId": "42b47cd3-aed1-4348-8c2c-6a97475c54bc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_community'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1447f68d0ced>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceInstructEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpgvector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPGVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextStreamer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from langchain import HuggingFacePipeline, PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores.pgvector import PGVector\n",
        "from transformers import AutoTokenizer, TextStreamer, pipeline\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiX57tzWOJAg"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjJ0DI9MRNkT"
      },
      "outputs": [],
      "source": [
        "embeddings = HuggingFaceInstructEmbeddings(\n",
        "    model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjPJro0W_CPE"
      },
      "source": [
        "load the existing vector db from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CUHxbG05oqU"
      },
      "outputs": [],
      "source": [
        "CONNECTION_STRING = \"***************\"\n",
        "\n",
        "store = PGVector(\n",
        "    connection_string=CONNECTION_STRING,\n",
        "    embedding_function=embeddings,\n",
        "    collection_name=\"Physicianai\",\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcylvlF60r_m"
      },
      "source": [
        "## Llama 2 13B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrSTLMQbfjFp"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model_basename = \"model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(\n",
        "    model_name_or_path,\n",
        "    revision=\"gptq-4bit-128g-actorder_True\",\n",
        "    model_basename=model_basename,\n",
        "    use_safetensors=True,\n",
        "    trust_remote_code=True,\n",
        "    inject_fused_attention=False,\n",
        "    device=DEVICE,\n",
        "    quantize_config=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nZmtsF3lAej"
      },
      "outputs": [],
      "source": [
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
        "You are a helpful, respectful and honest assistant. give answer for any questions.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_prompt(prompt: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
        "    return f\"\"\"\n",
        "[INST] <<SYS>>\n",
        "{system_prompt}\n",
        "<</SYS>>\n",
        "\n",
        "{prompt} [/INST]\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H6rPBpEAALY"
      },
      "outputs": [],
      "source": [
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYaQDkDvVvIz"
      },
      "outputs": [],
      "source": [
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=1024,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.15,\n",
        "    streamer=streamer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0sKzP77ZCok"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qawv0w1uEw38"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
        "\n",
        "template = generate_prompt(\n",
        "    \"\"\"\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\",\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJpTuSEoDDEJ"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DC-RU6DZCIS"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=store.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7IWZ6H1ax4z"
      },
      "source": [
        "## Chat with Multiple PDFs\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BR5nBf_fPao",
        "outputId": "2bfe3806-cc66-4f1a-d114-932a05b6a9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the given information, it is not possible to determine the exact cause of stomach pain after eating rice. However, there are several potential reasons why someone might experience stomach pain after consuming rice or any other food item. Some possible causes include:\n",
            "\n",
            "1. Food allergies or intolerances: Some people may be allergic or intolerant to certain ingredients in rice, such as gluten or lactose, which can cause digestive issues and stomach pain.\n",
            "2. Gastrointestinal issues: Conditions like irritable bowel syndrome (IBS), inflammatory bowel disease (IBD), and gastroesophageal reflux disease (GERD) can cause stomach pain and discomfort after eating certain foods, including rice.\n",
            "3. Infection or virus: Stomach pain can be a symptom of a bacterial or viral infection, such as food poisoning or a stomach flu.\n",
            "4. Dietary habits: Consuming large amounts of rice or other high-carbohydrate foods can lead to indigestion, bloating, and stomach pain in some individuals.\n",
            "5. Other medical conditions: Certain medical conditions, such as appendicitis, pancreatitis, or diverticulitis, can also cause stomach pain and discomfort.\n",
            "\n",
            "Without more specific information about the individual's medical history, dietary habits, and symptoms, it is difficult to pinpoint the exact cause of their stomach pain after eating rice. It is recommended that they consult with a healthcare professional for proper evaluation and diagnosis.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"im facing stomack pain after eat rice what is the reason?. if question is not related to provided data don't give answer from this provided data's\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyyiaN0yZ6LN",
        "outputId": "42e5b7ee-5de5-469e-970b-061971f3a60c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result[\"source_documents\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60qpCy_haA3D",
        "outputId": "54fc43fa-a762-4669-bb5a-1e473daf0d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meta Reports Second  Quarter 2023  Results\n",
            "MENLO PARK, Calif. – July 26, 2023  – Meta Platforms, Inc. (Nasdaq: META) today reported financial results for the \n",
            "quarter ended June 30, 2023 .\n",
            "\"We had a good quarter. We continue to see strong engagement across our apps and we have the most exciting roadmap I've \n",
            "seen in a while with Llama 2, Threads, Reels, new AI products in the pipeline, and the launch of Quest 3 this fall,\" said Mark \n",
            "Zuckerberg, Meta founder and CEO.\n",
            "Second Quarter 2023  Financial Highlights\n",
            "Three Months Ended June 30,\n",
            "In millions, except percentages and per share amounts 2023 2022 % Change\n",
            "Revenue $ 31,999 $ 28,822 11%\n",
            "Costs and expenses  22,607  20,464 10%\n",
            "Income from operations $ 9,392 $ 8,358 12%\n",
            "Operating margin  29 %  29 %\n",
            "Provision for income taxes $ 1,505 $ 1,499 —%\n",
            "Effective tax rate  16 %  18 %\n",
            "Net income $ 7,788 $ 6,687 16%\n",
            "Diluted earnings per share (EPS) $ 2.98 $ 2.46 21%\n",
            "Second Quarter 2023  Operational and Other Financial Highlights\n"
          ]
        }
      ],
      "source": [
        "print(result[\"source_documents\"][0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKmLM4UTfVmL",
        "outputId": "5917f98c-9716-4fbf-96ec-ab35fc493892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the information provided in the financial statements, the per share revenue for Tesla during 2023 can be calculated as follows:\n",
            "\n",
            "Total Revenue for 2023: $48,256 (from the Consolidated Statements of Operations)\n",
            "\n",
            "Number of shares outstanding: 249,270 (from the Balance Sheet)\n",
            "\n",
            "Per Share Revenue for 2023: $48,256 / 249,270 = $195.62\n",
            "\n",
            "Therefore, the per share revenue for Tesla during 2023 was $195.62.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the per share revenue for Tesla during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k96dxrgfjMr",
        "outputId": "433ce658-6976-47b6-d0c4-31edbbeaec3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the information provided in the financial statements, the per share revenue for Nvidia during 2023 was $0.83. This is calculated by dividing the total revenue for the period ($7,192 million) by the weighted average number of shares outstanding during the period (2,470 million).\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the per share revenue for Nvidia during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpMIspiSahlD",
        "outputId": "bcbf8a9b-f780-4d54-9628-574ae9980a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PART I. FINANCIAL INFORMATION\n",
            "ITEM 1.  FINANCIAL STATEMENTS (UNAUDITED)\n",
            "NVIDIA CORPORATION AND SUBSIDIARIES\n",
            "CONDENSED CONSOLIDATED STATEMENTS OF INCOME\n",
            "(In millions, except per share data)\n",
            "(Unaudited)\n",
            " Three Months Ended\n",
            " April 30, May 1,\n",
            "2023 2022\n",
            "Revenue $ 7,192 $ 8,288 \n",
            "Cost of revenue 2,544 2,857 \n",
            "Gross profit 4,648 5,431 \n",
            "Operating expenses   \n",
            "Research and development 1,875 1,618 \n",
            "Sales, general and administrative 633 592 \n",
            "Acquisition termination cost — 1,353 \n",
            "Total operating expenses 2,508 3,563 \n",
            "Income from operations 2,140 1,868 \n",
            "Interest income 150 18 \n",
            "Interest expense (66) (68)\n",
            "Other, net (15) (13)\n",
            "Other income (expense), net 69 (63)\n",
            "Income before income tax 2,209 1,805 \n",
            "Income tax expense 166 187 \n",
            "Net income $ 2,043 $ 1,618 \n",
            "Net income per share:\n",
            "Basic $ 0.83 $ 0.65 \n",
            "Diluted $ 0.82 $ 0.64 \n",
            "Weighted average shares used in per share computation:\n",
            "Basic 2,470 2,506 \n",
            "Diluted 2,490 2,537 \n",
            "See accompanying Notes to Condensed Consolidated Financial Statements.\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print(result[\"source_documents\"][1].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waIck-yefydp",
        "outputId": "0b64329e-2002-4816-a31e-0f157f959e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the information provided in the press release, Meta's estimated YOY revenue for 2023 is expected to be between $32-34.5 billion, which represents an increase of 11-16% over 2022.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the estimated YOY revenue for Meta during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq6cf8vof6wM",
        "outputId": "1b27e0a7-833d-4af0-c0ff-3d77da6acb6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the information provided in the quarterly report, the estimated year-over-year (YOY) revenue for Tesla during 2023 is not explicitly stated. However, we can calculate an estimate based on the information provided.\n",
            "\n",
            "For the six months ended June 30, 2023, Tesla's revenues were $41,231 million, representing a decrease of $768 million compared to the same period in 2022. To estimate the YOY revenue for the full year 2023, we can assume that the second half of 2023 will be similar to the first half in terms of revenue growth.\n",
            "\n",
            "Assuming no significant changes in market conditions or business operations, we can project the full-year 2023 revenue based on the first half's performance as follows:\n",
            "\n",
            "Full-year 2023 revenue = (First half 2023 revenue x 2) + (Second half 2022 revenue x 1)\n",
            "\n",
            "where \"Second half 2022 revenue\" represents the revenue generated during the last six months of 2022.\n",
            "\n",
            "Based on the information provided, the second half 2022 revenue was $35,690 million. Therefore, the estimated full-year 2023 revenue would be:\n",
            "\n",
            "Full-year 2023 revenue = ($41,231 million x 2) + ($35,690 million x 1)\n",
            "= $82,462 million + $35,690 million\n",
            "= $118,152 million\n",
            "\n",
            "This implies an estimated YOY revenue growth rate of approximately 25% for Tesla in 2023, based on the assumption that the second half of 2023 will be similar to the first half in terms of revenue growth. However, please note that this is only an estimate and actual results may vary due to various factors such as market conditions, product mix, and other business risks.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the estimated YOY revenue for Tesla during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIFTDoxzgY07",
        "outputId": "d231cabf-8c35-4a16-d660-9baf27280ed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the information provided, I cannot estimate the exact year-over-year (YOY) revenue for Nvidia during 2023. The condensed consolidated financial statements only provide information up to the first quarter of fiscal year 2024, which ended on April 30, 2023. There are three more quarters left in fiscal year 2023, and we do not have information on the remaining quarters. Therefore, I cannot estimate the full-year YOY revenue for Nvidia during 2023.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the estimated YOY revenue for Nvidia during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxp167huggFb",
        "outputId": "05b3eae5-2504-4520-c11d-d74d7547baf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I cannot determine which company is more profitable during 2023 between Meta, Nvidia, and Tesla based on the information provided. The passage only discusses Nvidia's financial condition and results of operations, but does not provide any information about Meta or Tesla's financial performance during 2023. Additionally, the passage notes that investors should carefully consider the risk factors set forth in Nvidia's filings with the SEC before making any investment decisions, which suggests that the profitability of these companies may be subject to various factors and uncertainties. Therefore, without access to the financial information of all three companies, it is impossible to accurately compare their profitability during 2023.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\n",
        "    \"Which company is more profitable during 2023 Meta, Nvidia or Tesla and why?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRuJYwSbgpij",
        "outputId": "36847349-76dd-429d-ea56-1927094de4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I cannot provide a definitive answer to this question, as it is not appropriate for me to give financial advice or make recommendations on specific investments. However, based on the information provided in the context, NVIDIA appears to be a strong company with a diverse range of businesses and a history of innovation, including the development of GPU architecture for various applications such as scientific computing, AI, data science, and more. Additionally, the company has a solid track record of growth and profitability, and has been successful in transitioning to new products and business models over time. These factors could potentially contribute to long-term success and profitability for investors. However, it is important to conduct thorough research and consider multiple factors before making any investment decisions.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\n",
        "    \"Choose one company to invest (Tesla, Nvidia or Meta) to maximize your profits for the long term (10+ years)?\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
